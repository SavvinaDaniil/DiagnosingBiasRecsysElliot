{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a83484-80a5-4772-9df2-52a45c40d8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\______/\\\\\\\\\\\\_________________________________________        \n",
      " _\\/\\\\\\///////////___\\////\\\\\\_____\\////\\\\\\_________________________________________       \n",
      "  _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\______/\\\\\\_____________________/\\\\\\______      \n",
      "   _\\/\\\\\\\\\\\\\\\\\\\\\\_________\\/\\\\\\________\\/\\\\\\_____\\///_______/\\\\\\\\\\______/\\\\\\\\\\\\\\\\\\\\\\_     \n",
      "    _\\/\\\\\\///////__________\\/\\\\\\________\\/\\\\\\______/\\\\\\____/\\\\\\///\\\\\\___\\////\\\\\\////__    \n",
      "     _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\_____\\/\\\\\\___/\\\\\\__\\//\\\\\\_____\\/\\\\\\______   \n",
      "      _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\_____\\/\\\\\\__\\//\\\\\\__/\\\\\\______\\/\\\\\\_/\\\\__  \n",
      "       _\\/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\\\\\\\__\\/\\\\\\___\\///\\\\\\\\\\/_______\\//\\\\\\\\\\___ \n",
      "        _\\///////////////___\\/////////___\\/////////___\\///______\\/////__________\\/////____\n",
      "Version Number: 0.3.1\n"
     ]
    }
   ],
   "source": [
    "from elliot.run import run_experiment\n",
    "from lib.data_generation import generate_data\n",
    "import zipfile\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import copy\n",
    "from lenskit import crossfold as xf\n",
    "import scipy\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12f851",
   "metadata": {},
   "source": [
    "### DMF experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1675b130",
   "metadata": {},
   "source": [
    "Generate train-test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341d1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e874f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"epinion\"\n",
    "mat = io.loadmat('data/epinion/epinion_events.mat')\n",
    "mat_df = pd.DataFrame(mat[\"rating_with_timestamp\"])\n",
    "mat_df.columns = [\"user\", \"item\", \".\", \"rating\", \"..\", \"...\"]\n",
    "ratings = mat_df[[\"user\", \"item\", \"rating\"]]\n",
    "ratings = ratings.drop_duplicates(subset=[\"user\", \"item\"], keep=\"last\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa707cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_splits = []\n",
    "data_strategy = 'epinion'\n",
    "\n",
    "sample = xf.SampleFrac(0.2, rng_spec=0)\n",
    "sets = [i for i in enumerate(xf.partition_users(ratings, 5, sample, rng_spec=0))]\n",
    "for j, tp in sets:\n",
    "    current_splits.append([tp[0], tp[1]])\n",
    "\n",
    "    tp[0].to_csv(\n",
    "        location + data_strategy + \"_fold_\" + str(j + 1) + \"_train.csv\", index=False\n",
    "    )\n",
    "    tp[1].to_csv(\n",
    "        location + data_strategy + \"_fold_\" + str(j + 1) + \"_test.csv\", index=False\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d89573",
   "metadata": {},
   "source": [
    "Change data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91a199a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    tr = pd.read_csv(\"data/epinion_fold_\"+str(i)+\"_train.csv\")\n",
    "    te = pd.read_csv(\"data/epinion_fold_\"+str(i)+\"_test.csv\")\n",
    "    np.savetxt(\"data/epinion_fold_\"+str(i)+\"_train.tsv\", tr,delimiter='\\t',fmt='%i')\n",
    "    np.savetxt(\"data/epinion_fold_\"+str(i)+\"_test.tsv\", te,delimiter='\\t',fmt='%i')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a97d36",
   "metadata": {},
   "source": [
    "Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8b5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible values for the hyperparameters\n",
    "mlp_values = ['(64,32)', '(64,64)']\n",
    "batch_size_values = [256, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad7c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start for  1 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "We re doing the following:  (64,32) 256\n",
      "2024-04-23 16:48:40.468404: I Start experiment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-23 16:48:40.771714: I /export/scratch2/home/savvina/new_environment/Elliot/elliot/data/epinion_fold_1_train.tsv - Loaded\n",
      "2024-04-23 16:48:41.010983: I Test Fold 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/epinion'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    for mlp in mlp_values:\n",
    "        for batch_size in batch_size_values:\n",
    "            print(\"We re doing the following: \", mlp, batch_size)\n",
    "            # Make a copy of the base configuration\n",
    "            config = copy.deepcopy(base_config)\n",
    "            # Update the configuration with the current hyperparameters\n",
    "            config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "            config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "            config['experiment']['models']['DMF']['batch_size'] = batch_size\n",
    "\n",
    "            # Write the configuration to a temporary file\n",
    "            with open('config_files/temp_config.yml', 'w') as f:\n",
    "                yaml.dump(config, f)\n",
    "\n",
    "            # Run the experiment with the current configuration\n",
    "            run_experiment('config_files/temp_config.yml')\n",
    "            \n",
    "            \n",
    "            # Remove the temp file\n",
    "            os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413065c4",
   "metadata": {},
   "source": [
    "TO do next:\n",
    "\n",
    "Extract the best iteration from the resulting file so you read the appropriate file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "889773d0e3910a3da9ca5cf13d401ea1cecb570772d2ad0802f95e8942400dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
