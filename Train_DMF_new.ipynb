{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32375f7a-3bb5-4a98-af36-1fe660a51dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\______/\\\\\\\\\\\\_________________________________________        \n",
      " _\\/\\\\\\///////////___\\////\\\\\\_____\\////\\\\\\_________________________________________       \n",
      "  _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\______/\\\\\\_____________________/\\\\\\______      \n",
      "   _\\/\\\\\\\\\\\\\\\\\\\\\\_________\\/\\\\\\________\\/\\\\\\_____\\///_______/\\\\\\\\\\______/\\\\\\\\\\\\\\\\\\\\\\_     \n",
      "    _\\/\\\\\\///////__________\\/\\\\\\________\\/\\\\\\______/\\\\\\____/\\\\\\///\\\\\\___\\////\\\\\\////__    \n",
      "     _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\_____\\/\\\\\\___/\\\\\\__\\//\\\\\\_____\\/\\\\\\______   \n",
      "      _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\_____\\/\\\\\\__\\//\\\\\\__/\\\\\\______\\/\\\\\\_/\\\\__  \n",
      "       _\\/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\\\\\\\__\\/\\\\\\___\\///\\\\\\\\\\/_______\\//\\\\\\\\\\___ \n",
      "        _\\///////////////___\\/////////___\\/////////___\\///______\\/////__________\\/////____\n",
      "Version Number: 0.3.1\n"
     ]
    }
   ],
   "source": [
    "from elliot.run import run_experiment\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446cf50-fc3c-4c00-aaae-82f89135a8f5",
   "metadata": {},
   "source": [
    "# Train Fairbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a96c0e-da11-42dc-ac3b-2ea52811eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'fairbook'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18dc1b1-ffa2-417e-a01b-74e14df9f217",
   "metadata": {},
   "source": [
    "1. Read best parameters\n",
    "2. Use best parameters for training by putting it in the yaml file.\n",
    "3. Train in the cross validation way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382d6ed8-10ca-48f8-b5b0-65b0b64c15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93127a97-9999-481a-b3aa-24b523081e1c",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e6b21-f1d3-4f51-935f-f52122cecab4",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe55a24-0d04-4c42-b743-b3ed1ac014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_01_08_46_55.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711eae8e-6a08-41fa-a215-ed1c4ed2537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b559ae-38d7-4e7b-b53f-dbfed5b8417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start for  1 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "2024-08-29 16:39:27.212025: I Start experiment\n",
      "2024-08-29 16:39:27.274853: I /export/scratch2/home/savvina/new_environment/Elliot/data/fairbook_fold_1_train.tsv - Loaded\n",
      "2024-08-29 16:39:27.291044: I Test Fold 0\n",
      "2024-08-29 16:39:32.804537: I Statistics\tUsers:\t6358\tItems:\t6921\tTransactions:\t85028\tSparsity:\t0.9980677087331575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 16:39:35.867199: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2024-08-29 16:39:35.867240: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-29 16:39:36.969490: I Training begun for DMF\\n\n",
      "2024-08-29 16:39:36.969346: I Loading parameters\n",
      "2024-08-29 16:39:36.971593: I Hyperparameters:\n",
      "2024-08-29 16:39:36.972821: I Parameter lr set to 0.1\n",
      "2024-08-29 16:39:36.972977: I batch_size set to 1024\n",
      "2024-08-29 16:39:36.974523: I Parameter user_mlp set to [64, 64]\n",
      "2024-08-29 16:39:36.975783: I Parameter item_mlp set to [64, 64]\n",
      "2024-08-29 16:39:36.975961: I epochs set to 25\n",
      "2024-08-29 16:39:36.977269: I Parameter neg_ratio set to 5\n",
      "2024-08-29 16:39:36.978307: I item_mlp set to (64,64)\n",
      "2024-08-29 16:39:36.978569: I Parameter reg set to 0.001\n",
      "2024-08-29 16:39:36.979764: I Parameter similarity set to cosine\n",
      "2024-08-29 16:39:36.980980: I lr set to 0.1\n",
      "2024-08-29 16:39:36.982573: I meta set to namespace(save_recs=True)\n",
      "2024-08-29 16:39:37.001868: I n_fold set to 1\n",
      "2024-08-29 16:39:37.085334: I similarity set to cosine\n",
      "2024-08-29 16:39:37.129144: I user_mlp set to (64,64)\n",
      "2024-08-29 16:39:37.131789: I Exploration: Test Fold exploration number 1\n",
      "2024-08-29 16:39:37.137103: I Exploration: Train-Validation Fold exploration number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 16:39:37.091586: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-08-29 16:39:37.091628: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-08-29 16:39:37.091658: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alice.ia.cwi.nl): /proc/driver/nvidia/version does not exist\n",
      "2024-08-29 16:39:37.091864: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 16:39:37.107529: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1996165000 Hz\n",
      "2024-08-29 16:39:37.115918: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x51431e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-29 16:39:37.115971: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-08-29 16:40:00.157292: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 196199387136 exceeds 10% of free system memory.\n",
      "2024-08-29 16:40:00.157381: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 180239228928 exceeds 10% of free system memory.\n",
      "2024-08-29 16:41:18.793506: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 180239228928 exceeds 10% of free system memory.\n",
      "2024-08-29 16:41:18.793506: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 196199387136 exceeds 10% of free system memory.\n",
      "2024-08-29 16:42:36.680714: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 196199387136 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-29 16:48:06.408252: I \n",
      "2024-08-29 16:48:06.407989: I Epoch 1/25 loss 334.87299\n",
      "2024-08-29 16:48:06.411361: I Writing recommendations at: /export/scratch2/home/savvina/new_environment/Elliot/results/fairbook1/recs\n",
      "2024-08-29 16:48:06.411577: I Test Evaluation results\n",
      "2024-08-29 16:48:06.413048: I Cut-off: 10\n",
      "2024-08-29 16:48:06.415510: I Eval Time: 0.16827178001403809\n",
      "2024-08-29 16:48:06.539117: I ******************************************\n",
      "2024-08-29 16:48:06.539361: I Results\n",
      "2024-08-29 16:48:06.540919: I nDCG\t0.00135\n",
      "2024-08-29 16:56:31.692669: I \n",
      "2024-08-29 16:56:31.692323: I Epoch 2/25 loss 49.61535\n",
      "2024-08-29 16:56:31.699305: I Writing recommendations at: /export/scratch2/home/savvina/new_environment/Elliot/results/fairbook1/recs\n",
      "2024-08-29 16:56:31.699659: I Test Evaluation results\n",
      "2024-08-29 16:56:31.701059: I Cut-off: 10\n",
      "2024-08-29 16:56:31.702468: I Eval Time: 0.0225217342376709\n",
      "2024-08-29 16:56:31.705181: I Results\n",
      "2024-08-29 16:56:31.843810: I ******************************************\n",
      "2024-08-29 16:56:31.852665: I nDCG\t0.0015\n",
      "2024-08-29 17:04:54.418051: I \n",
      "2024-08-29 17:04:54.417846: I Epoch 3/25 loss 21.87517\n",
      "2024-08-29 17:04:54.422026: I Writing recommendations at: /export/scratch2/home/savvina/new_environment/Elliot/results/fairbook1/recs\n",
      "2024-08-29 17:04:54.422224: I Test Evaluation results\n",
      "2024-08-29 17:04:54.423622: I Cut-off: 10\n",
      "2024-08-29 17:04:54.572379: I Eval Time: 0.022812843322753906\n",
      "2024-08-29 17:04:54.587466: I Results\n",
      "2024-08-29 17:04:54.592581: I nDCG\t0.00139\n",
      "2024-08-29 17:13:21.648765: I \n",
      "2024-08-29 17:13:21.648673: I Epoch 4/25 loss 12.28935\n",
      "2024-08-29 17:13:21.650587: I Writing recommendations at: /export/scratch2/home/savvina/new_environment/Elliot/results/fairbook1/recs\n",
      "2024-08-29 17:13:21.650750: I Test Evaluation results\n",
      "2024-08-29 17:13:21.652130: I Cut-off: 10\n",
      "2024-08-29 17:13:21.664450: I Eval Time: 0.022855758666992188\n",
      "2024-08-29 17:13:21.714514: I Results\n",
      "2024-08-29 17:13:21.759178: I nDCG\t0.00114\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/fairbook'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6ffca-babe-43ef-acbe-c19a60901dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ed0b86-a7ac-442f-bb4a-c3f128a8442c",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bc0b31-b43f-43f0-a1e7-e5b7b1ac5ea2",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84f085-ea88-49b8-8745-ec78ec733dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_07_31_11_32_14.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6694caa8-61e1-4ecf-b93e-e7b665129bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a007953-f9a2-429b-825a-5ce6db15346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/fairbook'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a7797-4636-4c93-ada9-2c337b37e4ae",
   "metadata": {},
   "source": [
    "# Train ML1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7813e95f-b792-4776-b700-ea4faf8b2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'ml1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aecb789-aaf7-4ef5-b673-b60d35dab2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca4746-2e75-4c8d-a253-0dfae1f727bd",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8479d-0a1d-4906-90b8-02f80057921e",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b023b4e1-b875-4e2f-a4dc-e923b558cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_28_14_17_42.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf1e8a1-5ca8-416e-b1a5-d4cb43944b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b74519-b9a0-4d85-b9a9-5cdfcf6b29bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start for  1 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "2024-09-03 13:10:00.592925: I Start experiment\n",
      "2024-09-03 13:10:00.872724: I /export/scratch2/home/savvina/new_environment/Elliot/data/ml1m_fold_1_train.tsv - Loaded\n",
      "2024-09-03 13:10:00.921375: I Test Fold 0\n",
      "2024-09-03 13:10:17.221913: I Statistics\tUsers:\t6040\tItems:\t3701\tTransactions:\t959649\tSparsity:\t0.9570704445370949\n",
      "2024-09-03 13:10:20.965625: I Training begun for DMF\\n\n",
      "2024-09-03 13:10:20.972219: I Hyperparameters:\n",
      "2024-09-03 13:10:21.048777: I batch_size set to 1024\n",
      "2024-09-03 13:10:21.052561: I epochs set to 25\n",
      "2024-09-03 13:10:21.055276: I item_mlp set to (64,64)\n",
      "2024-09-03 13:10:21.056813: I lr set to 0.1\n",
      "2024-09-03 13:10:21.058410: I meta set to namespace(save_recs=True)\n",
      "2024-09-03 13:10:21.060060: I n_fold set to 1\n",
      "2024-09-03 13:10:21.063322: I similarity set to cosine\n",
      "2024-09-03 13:10:21.064829: I user_mlp set to (64,64)\n",
      "2024-09-03 13:10:21.067365: I Exploration: Test Fold exploration number 1\n",
      "2024-09-03 13:10:21.068802: I Exploration: Train-Validation Fold exploration number 1\n",
      "2024-09-03 13:17:10.478433: I \n",
      "2024-09-03 13:17:10.612696: I Test Evaluation results\n",
      "2024-09-03 13:17:10.627704: I Cut-off: 10\n",
      "2024-09-03 13:17:10.629609: I Eval Time: 0.04543304443359375\n",
      "2024-09-03 13:17:10.631296: I Results\n",
      "2024-09-03 13:17:10.632855: I nDCG\t0.00341\n",
      "2024-09-03 13:23:54.804325: I \n",
      "2024-09-03 13:23:54.874401: I Test Evaluation results\n",
      "2024-09-03 13:23:54.931892: I Cut-off: 10\n",
      "2024-09-03 13:23:54.955318: I Eval Time: 0.02901005744934082\n",
      "2024-09-03 13:23:54.956644: I Results\n",
      "2024-09-03 13:23:54.957910: I nDCG\t0.00758\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/ml1m'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0fe1e-7b58-4b6d-907c-91812546bebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39339535-283d-4b99-a2c8-d652fbf05a5d",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46acbd-6f09-4048-bcac-d1cb0962ed6a",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda9425-65a1-4fe6-86d7-391c1fe2c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_28_03_24_41.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ccf4d-4e9c-4660-8069-9da85da1a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40dd0d-537f-4fb3-a594-c67c4e2b7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/ml1m'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c84de6-9100-46d6-bf65-e4616d0a89e5",
   "metadata": {},
   "source": [
    "# Train Synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bca63-3da5-47bf-b4b8-ec80dc63447e",
   "metadata": {},
   "source": [
    "## Train UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773be14-3e6c-4b5b-97de-ff441506b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'uniformly_random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec66de-c627-4add-81ec-d8c160b08283",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d598e-26c0-4773-aeef-8d3fd20dec40",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbd0c6-305a-4ea7-a6e9-dbcb1c2c4458",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63074a3f-70c4-4f64-98d7-d9b862ac3f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_04_02_27_21.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ededae1-688a-47fc-be80-6dc4728f0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40347973-31bf-4c0a-8e45-19508fdaaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/uniformly_random'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997ebf6-b2f3-4feb-8a16-7a8fa8c5030f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f705f73-dd83-46a3-abd9-c561531fbd61",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1c56e-c406-43e5-9ab4-ff43f500b382",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3dfa6-0471-4e5c-99ac-7e936107f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_03_06_56_39.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22901bfc-d3e5-4144-a08a-2cc99982f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d24d43-b62b-4114-9852-f4cb85cbe265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/uniformly_random'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe273c4e-1f8d-4b0b-a56e-fe8cf75e930b",
   "metadata": {},
   "source": [
    "## Train Popularity good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1989b-eb86-4600-bb48-0d9153b862e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'popularity_good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f8458-1e80-4679-bb9d-d906416460ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956e91bf-b86f-43f5-9ec9-4f0edaabb5cb",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0eb4f4-816d-413e-89cb-620245caf1ef",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29518672-3449-49ee-afd6-3635be9e668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_05_16_39_20.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eeb198-80f9-4444-a801-ac2a6090c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2822559b-ce10-4432-ba73-389b7e6feb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_good'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8783d8e-c802-4c52-a49b-acdbf9e12be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e7d4b2-4d6c-46b5-b596-539f36b11fc2",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942268e-25b1-4ad4-842d-f10f7bccdc2d",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbfd6d-d327-4eb6-8b12-615b2ac6603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_04_21_29_55.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff71ba5-4f04-439e-a3eb-c8d7de3b5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9298faf-15e9-49fd-83e8-177a3c77a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_good'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0355e-c20c-4dcc-a94b-a646dabf2af5",
   "metadata": {},
   "source": [
    "## Train Popularity bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19a505-9252-4f28-995a-43ddaeff906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'popularity_bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2d04f-f304-423b-b86b-7022dc6588ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa17964-52d4-4947-8b55-9b27b7581fa8",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c25e6-a620-40c2-a31e-fac1678d80cc",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78f9c3-14dc-4f5f-b5ed-277373c232df",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_07_06_34_11.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ecee5-98bd-4a20-a5c6-d59b4065bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca379af-50f1-4881-909a-117ad06b8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_bad'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f592d-d8f7-4945-b999-b727180eadbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2e809b0-8dbb-41b7-900b-73baccbefe9d",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e0560-9a6e-4d82-b6cb-ac26500e518e",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bc376-18f3-4ad5-b3ba-58eed83cf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_06_11_31_53.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04327a48-dcad-4edb-a8f0-b2d4888825de",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e09ca9-423c-4cd0-a506-0af5425147bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_bad'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59222a-bf6a-47a0-a52f-06874bd8f4ab",
   "metadata": {},
   "source": [
    "## Train Popularity good big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b9b8f-3f03-44a5-8497-e72ded92b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'popularity_good_for_bp_ur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6561fe-74bb-4eaa-adbe-07a971fb7420",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d97fb-de2d-4d92-beab-d659731075c1",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a8077-6d4d-4d45-8860-20d221d829a6",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49e420-7385-435f-8b56-bb73b7f2b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_08_15_33_01.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c0acc-8def-4104-8261-4a7dd43850f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452bd5b8-4c0a-4619-9648-8ec645a30ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_good_big'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30167af4-4b52-4bfe-8be6-d694aca67664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9d62769-fc65-483d-ac01-07838c4628ee",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113ce69-a007-4517-9fca-6f8ffb1c43a4",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafba6f6-5100-45ea-a5ae-03ff65da63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_07_23_47_02.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d3d943-9f61-45d6-874f-071b48636e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273975b-767a-47ff-8cca-95c304676767",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_good_big'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12873f2e-164b-4162-9f70-0f5ec473a5a3",
   "metadata": {},
   "source": [
    "## Train Popularity bad big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99be2fe-5764-4b8b-889c-ef03c36d3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'popularity_bad_for_bp_ur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c39d2-77a4-4474-afb4-37b74098f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71310efe-9b8d-462f-87b3-7bb47cada56c",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8fd5db-ebf2-4b29-b989-f7b0b3d1e5cc",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f0a0e-c8dc-4500-a706-20f5120773be",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_09_21_07_34.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a48a9-43e9-4cdb-bb73-9919581e8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf30c93-fb77-4c9d-ba27-1dd637f8317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_bad_big'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234df206-ea9e-41c1-8ca4-8752b9073d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ba02eff-460c-43b6-b069-d6e0af0035a9",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbc50d-62eb-4b9a-aa80-2d5b5cb03008",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a5a94-b08c-41f4-a27f-de1e055b798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_09_06_37_14.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96e8fd-563e-4df8-88e7-1eadd2ae6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1109fd-6671-46f4-beb1-99e369a99dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_bad_big'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6c1cd-f325-4b1c-b2a3-9a887d43f68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
