{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32375f7a-3bb5-4a98-af36-1fe660a51dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\______/\\\\\\\\\\\\_________________________________________        \n",
      " _\\/\\\\\\///////////___\\////\\\\\\_____\\////\\\\\\_________________________________________       \n",
      "  _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\______/\\\\\\_____________________/\\\\\\______      \n",
      "   _\\/\\\\\\\\\\\\\\\\\\\\\\_________\\/\\\\\\________\\/\\\\\\_____\\///_______/\\\\\\\\\\______/\\\\\\\\\\\\\\\\\\\\\\_     \n",
      "    _\\/\\\\\\///////__________\\/\\\\\\________\\/\\\\\\______/\\\\\\____/\\\\\\///\\\\\\___\\////\\\\\\////__    \n",
      "     _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\_____\\/\\\\\\___/\\\\\\__\\//\\\\\\_____\\/\\\\\\______   \n",
      "      _\\/\\\\\\_________________\\/\\\\\\________\\/\\\\\\_____\\/\\\\\\__\\//\\\\\\__/\\\\\\______\\/\\\\\\_/\\\\__  \n",
      "       _\\/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\\\\\\\___/\\\\\\\\\\\\\\\\\\__\\/\\\\\\___\\///\\\\\\\\\\/_______\\//\\\\\\\\\\___ \n",
      "        _\\///////////////___\\/////////___\\/////////___\\///______\\/////__________\\/////____\n",
      "Version Number: 0.3.1\n"
     ]
    }
   ],
   "source": [
    "from elliot.run import run_experiment\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79bbb22f-5ffd-4581-ac06-94d41b8f339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(dataset):\n",
    "    if dataset == 'fairbook':\n",
    "        train_fairbook()\n",
    "    elif dataset == 'ml1m':\n",
    "        train_ml1m()\n",
    "    elif dataset == 'epinion':\n",
    "        train_epinion()\n",
    "    elif dataset == 'synthetic':\n",
    "        train_synthetic()\n",
    "    else:\n",
    "        print(\"Error! This is not one of the available datasets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446cf50-fc3c-4c00-aaae-82f89135a8f5",
   "metadata": {},
   "source": [
    "# Train Fairbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a268a98-5b48-4d09-900c-bcbdac030c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d66d5-e552-4954-9584-14db3b8953cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc964f-72b7-444e-8c0e-a921fde435ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc13c17-4e16-45b6-88ff-72041c628079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1d62c-8da7-4aed-bf7d-d60b06832612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fairbook():\n",
    "    data = 'fairbook'\n",
    "    location = 'results/'+data+'/performance/'\n",
    "    filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_01_08_46_55.json'\n",
    "    file = location + filename\n",
    "    with open(file) as f:\n",
    "        d = json.load(f)\n",
    "        mlp = d[1]['configuration']['item_mlp']\n",
    "        assert mlp == '(64,64)'\n",
    "        best_lr = d[1]['configuration']['lr']\n",
    "    for i in range(1, 6):\n",
    "        print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        with open('config_files/fairbook'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "            base_config = yaml.safe_load(f)\n",
    "        \n",
    "        \n",
    "        # Make a copy of the base configuration\n",
    "        config = copy.deepcopy(base_config)\n",
    "        # Update the configuration with the current hyperparameters\n",
    "        config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "        config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "        config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "    \n",
    "        # Write the configuration to a temporary file\n",
    "        with open('config_files/temp_config.yml', 'w') as f:\n",
    "            yaml.dump(config, f)\n",
    "    \n",
    "        # Run the experiment with the current configuration\n",
    "        run_experiment('config_files/temp_config.yml')\n",
    "        \n",
    "        \n",
    "        # Remove the temp file\n",
    "        os.remove('config_files/temp_config.yml')\n",
    "\n",
    "    filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_07_31_11_32_14.json'\n",
    "    file = location + filename\n",
    "    with open(file) as f:\n",
    "        d = json.load(f)\n",
    "        mlp = d[1]['configuration']['item_mlp']\n",
    "        assert mlp == '(64,32)'\n",
    "        best_lr = d[1]['configuration']['lr']\n",
    "    for i in range(1, 6):\n",
    "        print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "        with open('config_files/fairbook'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "            base_config = yaml.safe_load(f)\n",
    "        \n",
    "        \n",
    "        # Make a copy of the base configuration\n",
    "        config = copy.deepcopy(base_config)\n",
    "        # Update the configuration with the current hyperparameters\n",
    "        config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "        config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "        config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "    \n",
    "        # Write the configuration to a temporary file\n",
    "        with open('config_files/temp_config.yml', 'w') as f:\n",
    "            yaml.dump(config, f)\n",
    "    \n",
    "        # Run the experiment with the current configuration\n",
    "        run_experiment('config_files/temp_config.yml')\n",
    "        \n",
    "        \n",
    "        # Remove the temp file\n",
    "        os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a7797-4636-4c93-ada9-2c337b37e4ae",
   "metadata": {},
   "source": [
    "# Train ML1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7813e95f-b792-4776-b700-ea4faf8b2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'ml1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aecb789-aaf7-4ef5-b673-b60d35dab2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ca4746-2e75-4c8d-a253-0dfae1f727bd",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8479d-0a1d-4906-90b8-02f80057921e",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b023b4e1-b875-4e2f-a4dc-e923b558cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_28_14_17_42.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf1e8a1-5ca8-416e-b1a5-d4cb43944b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b74519-b9a0-4d85-b9a9-5cdfcf6b29bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start for  1 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "2024-09-03 13:10:00.592925: I Start experiment\n",
      "2024-09-03 13:10:00.872724: I /export/scratch2/home/savvina/new_environment/Elliot/data/ml1m_fold_1_train.tsv - Loaded\n",
      "2024-09-03 13:10:00.921375: I Test Fold 0\n",
      "2024-09-03 13:10:17.221913: I Statistics\tUsers:\t6040\tItems:\t3701\tTransactions:\t959649\tSparsity:\t0.9570704445370949\n",
      "2024-09-03 13:10:20.965625: I Training begun for DMF\\n\n",
      "2024-09-03 13:10:20.972219: I Hyperparameters:\n",
      "2024-09-03 13:10:21.048777: I batch_size set to 1024\n",
      "2024-09-03 13:10:21.052561: I epochs set to 25\n",
      "2024-09-03 13:10:21.055276: I item_mlp set to (64,64)\n",
      "2024-09-03 13:10:21.056813: I lr set to 0.1\n",
      "2024-09-03 13:10:21.058410: I meta set to namespace(save_recs=True)\n",
      "2024-09-03 13:10:21.060060: I n_fold set to 1\n",
      "2024-09-03 13:10:21.063322: I similarity set to cosine\n",
      "2024-09-03 13:10:21.064829: I user_mlp set to (64,64)\n",
      "2024-09-03 13:10:21.067365: I Exploration: Test Fold exploration number 1\n",
      "2024-09-03 13:10:21.068802: I Exploration: Train-Validation Fold exploration number 1\n",
      "2024-09-03 13:17:10.478433: I \n",
      "2024-09-03 13:17:10.612696: I Test Evaluation results\n",
      "2024-09-03 13:17:10.627704: I Cut-off: 10\n",
      "2024-09-03 13:17:10.629609: I Eval Time: 0.04543304443359375\n",
      "2024-09-03 13:17:10.631296: I Results\n",
      "2024-09-03 13:17:10.632855: I nDCG\t0.00341\n",
      "2024-09-03 13:23:54.804325: I \n",
      "2024-09-03 13:23:54.874401: I Test Evaluation results\n",
      "2024-09-03 13:23:54.931892: I Cut-off: 10\n",
      "2024-09-03 13:23:54.955318: I Eval Time: 0.02901005744934082\n",
      "2024-09-03 13:23:54.956644: I Results\n",
      "2024-09-03 13:23:54.957910: I nDCG\t0.00758\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/ml1m'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0fe1e-7b58-4b6d-907c-91812546bebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39339535-283d-4b99-a2c8-d652fbf05a5d",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46acbd-6f09-4048-bcac-d1cb0962ed6a",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda9425-65a1-4fe6-86d7-391c1fe2c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_28_03_24_41.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ccf4d-4e9c-4660-8069-9da85da1a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40dd0d-537f-4fb3-a594-c67c4e2b7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/ml1m'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c84de6-9100-46d6-bf65-e4616d0a89e5",
   "metadata": {},
   "source": [
    "# Train Synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bca63-3da5-47bf-b4b8-ec80dc63447e",
   "metadata": {},
   "source": [
    "## Train UR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773be14-3e6c-4b5b-97de-ff441506b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'uniformly_random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec66de-c627-4add-81ec-d8c160b08283",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d598e-26c0-4773-aeef-8d3fd20dec40",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbd0c6-305a-4ea7-a6e9-dbcb1c2c4458",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63074a3f-70c4-4f64-98d7-d9b862ac3f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_04_02_27_21.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ededae1-688a-47fc-be80-6dc4728f0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40347973-31bf-4c0a-8e45-19508fdaaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/uniformly_random'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997ebf6-b2f3-4feb-8a16-7a8fa8c5030f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f705f73-dd83-46a3-abd9-c561531fbd61",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1c56e-c406-43e5-9ab4-ff43f500b382",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3dfa6-0471-4e5c-99ac-7e936107f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_03_06_56_39.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22901bfc-d3e5-4144-a08a-2cc99982f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d24d43-b62b-4114-9852-f4cb85cbe265",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/uniformly_random'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe273c4e-1f8d-4b0b-a56e-fe8cf75e930b",
   "metadata": {},
   "source": [
    "## Train Popularity good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1989b-eb86-4600-bb48-0d9153b862e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'popularity_good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f8458-1e80-4679-bb9d-d906416460ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956e91bf-b86f-43f5-9ec9-4f0edaabb5cb",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0eb4f4-816d-413e-89cb-620245caf1ef",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29518672-3449-49ee-afd6-3635be9e668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_05_16_39_20.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eeb198-80f9-4444-a801-ac2a6090c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2822559b-ce10-4432-ba73-389b7e6feb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_good'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8783d8e-c802-4c52-a49b-acdbf9e12be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e7d4b2-4d6c-46b5-b596-539f36b11fc2",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942268e-25b1-4ad4-842d-f10f7bccdc2d",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbfd6d-d327-4eb6-8b12-615b2ac6603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_04_21_29_55.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff71ba5-4f04-439e-a3eb-c8d7de3b5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9298faf-15e9-49fd-83e8-177a3c77a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_good'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0355e-c20c-4dcc-a94b-a646dabf2af5",
   "metadata": {},
   "source": [
    "## Train Popularity bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19a505-9252-4f28-995a-43ddaeff906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'popularity_bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2d04f-f304-423b-b86b-7022dc6588ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa17964-52d4-4947-8b55-9b27b7581fa8",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c25e6-a620-40c2-a31e-fac1678d80cc",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78f9c3-14dc-4f5f-b5ed-277373c232df",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_07_06_34_11.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ecee5-98bd-4a20-a5c6-d59b4065bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca379af-50f1-4881-909a-117ad06b8e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_bad'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f592d-d8f7-4945-b999-b727180eadbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2e809b0-8dbb-41b7-900b-73baccbefe9d",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e0560-9a6e-4d82-b6cb-ac26500e518e",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bc376-18f3-4ad5-b3ba-58eed83cf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_06_11_31_53.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04327a48-dcad-4edb-a8f0-b2d4888825de",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e09ca9-423c-4cd0-a506-0af5425147bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_bad'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59222a-bf6a-47a0-a52f-06874bd8f4ab",
   "metadata": {},
   "source": [
    "## Train Popularity good big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b9b8f-3f03-44a5-8497-e72ded92b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'popularity_good_for_bp_ur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6561fe-74bb-4eaa-adbe-07a971fb7420",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d97fb-de2d-4d92-beab-d659731075c1",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a8077-6d4d-4d45-8860-20d221d829a6",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49e420-7385-435f-8b56-bb73b7f2b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_08_15_33_01.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c0acc-8def-4104-8261-4a7dd43850f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452bd5b8-4c0a-4619-9648-8ec645a30ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_good_big'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30167af4-4b52-4bfe-8be6-d694aca67664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9d62769-fc65-483d-ac01-07838c4628ee",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113ce69-a007-4517-9fca-6f8ffb1c43a4",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafba6f6-5100-45ea-a5ae-03ff65da63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_07_23_47_02.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d3d943-9f61-45d6-874f-071b48636e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9273975b-767a-47ff-8cca-95c304676767",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_good_big'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12873f2e-164b-4162-9f70-0f5ec473a5a3",
   "metadata": {},
   "source": [
    "## Train Popularity bad big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99be2fe-5764-4b8b-889c-ef03c36d3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'popularity_bad_for_bp_ur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c39d2-77a4-4474-afb4-37b74098f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'results/'+data+'/performance/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71310efe-9b8d-462f-87b3-7bb47cada56c",
   "metadata": {},
   "source": [
    "64 - 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8fd5db-ebf2-4b29-b989-f7b0b3d1e5cc",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f0a0e-c8dc-4500-a706-20f5120773be",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_09_21_07_34.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a48a9-43e9-4cdb-bb73-9919581e8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,64)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf30c93-fb77-4c9d-ba27-1dd637f8317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_bad_big'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234df206-ea9e-41c1-8ca4-8752b9073d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ba02eff-460c-43b6-b069-d6e0af0035a9",
   "metadata": {},
   "source": [
    "64 - 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbc50d-62eb-4b9a-aa80-2d5b5cb03008",
   "metadata": {},
   "source": [
    "Set filename manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a5a94-b08c-41f4-a27f-de1e055b798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestmodelparams_cutoff_10_relthreshold_0_2024_08_09_06_37_14.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96e8fd-563e-4df8-88e7-1eadd2ae6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = location + filename\n",
    "with open(file) as f:\n",
    "    d = json.load(f)\n",
    "    mlp = d[1]['configuration']['item_mlp']\n",
    "    assert mlp == '(64,32)'\n",
    "    best_lr = d[1]['configuration']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1109fd-6671-46f4-beb1-99e369a99dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    print('Start for ', i, '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "    with open('config_files/popularity_bad_big'+str(i)+'.yml', 'r') as f: # open the relevant yaml file\n",
    "        base_config = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    # Make a copy of the base configuration\n",
    "    config = copy.deepcopy(base_config)\n",
    "    # Update the configuration with the current hyperparameters\n",
    "    config['experiment']['models']['DMF']['user_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['item_mlp'] = mlp\n",
    "    config['experiment']['models']['DMF']['lr'] = best_lr\n",
    "\n",
    "    # Write the configuration to a temporary file\n",
    "    with open('config_files/temp_config.yml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    # Run the experiment with the current configuration\n",
    "    run_experiment('config_files/temp_config.yml')\n",
    "    \n",
    "    \n",
    "    # Remove the temp file\n",
    "    os.remove('config_files/temp_config.yml')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6c1cd-f325-4b1c-b2a3-9a887d43f68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
