{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd444844-df50-4c96-ab01-1f612d412143",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80cc8654-7b7e-4f89-9ca1-9795e17e5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from lib import modelling_mf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e63b30-e639-4ee5-96b2-2796bad9394c",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a350c33-6d43-48a8-9474-fd116a5d416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'DMF'\n",
    "batch_size = 1024\n",
    "\n",
    "user_col = \"user\" # the name of the column that includes the users\n",
    "item_col = \"item\" # the name of the column that includes the items\n",
    "predict_col=\"rating\" # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f77cbb-112c-4406-876b-434774530b84",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0fc6f-1de5-4db9-b6be-67726f0c2153",
   "metadata": {},
   "source": [
    "## A. Fairbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7374915e-f03b-48d8-8a08-2d3a4dd4bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These change for every dataser\n",
    "data = 'fairbook'\n",
    "ratings = pd.read_csv(\"data/\"+data+\"/\"+data+\"_events.csv\")\n",
    "all_items=set(ratings.item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "367e3e76-7173-4355-ba82-46fd9417adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recs_files = {}\n",
    "for fold in range(1,6):\n",
    "\n",
    "\n",
    "    # Set locations of recommendations and best iteration files\n",
    "    recs_location = 'results/'+data+str(fold)+'/recs/'\n",
    "    best_iter_location = 'results/'+data+str(fold)+'/performance/'\n",
    "    \n",
    "    # Find all json files in the folder (they contain the best iterations).\n",
    "    bestmodelparams_files = [best_iter_location + pos_json for pos_json in os.listdir(best_iter_location) if pos_json.endswith('.json')]\n",
    "\n",
    "    # For every json find the mlp value and the equivalent best iteration and learning rate (which was set after hyperparameter tuning).\n",
    "    best_iters = {}\n",
    "    for file in bestmodelparams_files:\n",
    "        with open(file) as f:\n",
    "            d = json.load(f)\n",
    "        mlp = d[1]['configuration']['item_mlp']\n",
    "        best_iteration = d[1]['configuration']['best_iteration']\n",
    "        lr = d[1]['configuration']['lr'] # this was found in a previous step, not during training\n",
    "        best_iters[mlp] = (lr, best_iteration)\n",
    "        \n",
    "    # For every mlp value, find the file that contains the recommendations.\n",
    "    mlp_values = best_iters.keys()\n",
    "    \n",
    "    for mlp in mlp_values:\n",
    "        lr = str(best_iters[mlp][0]).replace('.','$')\n",
    "        bi = str(best_iters[mlp][1])\n",
    "        mlp = mlp.replace(',','-').replace('(','').replace(')','')\n",
    "        recs_file = recs_location + algorithm+'_seed=42_e=25_bs='+str(batch_size)+'_lr='+lr+'_umlp='+mlp+'_imlp='+mlp+'_negratio=5_reg=0$001_sim=cosine_it='+bi+'.tsv'\n",
    "        final_recs_files[fold,mlp] = recs_file\n",
    "    mlp_values = np.unique([x[1] for x in final_recs_files.keys()]) # change the format   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dde05be-a8b8-4a7a-96c0-733f4b6bc7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64-32\n",
      "nr of longtail 7104\n",
      "5.584905660377358\n"
     ]
    }
   ],
   "source": [
    "for mlp in mlp_values:\n",
    "    print(mlp)\n",
    "    metrics = []\n",
    "    for fold in range(1,6):\n",
    "        # Train and test files of that fold\n",
    "        train_file = 'data/'+data+'_fold_'+str(fold)+'_train.csv'\n",
    "        test_file = 'data/'+data+'_fold_'+str(fold)+'_test.csv'\n",
    "    \n",
    "        train_df = pd.read_csv(train_file)\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        test_users = test_df.user.unique()\n",
    "\n",
    "        # Recommendations\n",
    "        recs_file = final_recs_files[fold,mlp]\n",
    "        recs_df = pd.read_csv(recs_file, sep='\\t', header=None)\n",
    "        recs_df.columns = ['user','item','rating']\n",
    "\n",
    "        # Test recommendations\n",
    "        test_recs = recs_df[recs_df.user.isin(test_users)].reset_index(drop=True)\n",
    "        test_recs_grouped = test_recs.groupby([user_col])[item_col].apply(list)\n",
    "\n",
    "        # Calculate all metrics\n",
    "        pop_bias= modelling_mf.calculate_pop_bias_per_item(all_items, item_col, user_col, predict_col, train_df, recs=test_recs)\n",
    "        GAP_vs_GAP = modelling_mf.calculate_ave_pop_per_user(test_users, item_col, user_col, pop_bias, train_df, test_recs_grouped)\n",
    "        pop_corr = modelling_mf.calculate_pop_correlation(pop_bias)\n",
    "        precision, recall, ndcg = modelling_mf.calculate_topn_metrics(test_recs,test_df)\n",
    "        AggDiv = modelling_mf.evaluate_item_coverage(pop_bias[\"recommendation\"].values)\n",
    "        ARP, ave_PL, ACLT = modelling_mf.calculate_all_pb_metrics(pop_bias, test_users, item_col, user_col, train_df, test_recs_grouped, test_recs)\n",
    "        metrics_dict = {\"pop_corr\":pop_corr, \"RMSE\":0, 'NDCG':ndcg,\"ARP\":ARP, \"ave_PL\": ave_PL, \"ACLT\": ACLT, \"AggDiv\": AggDiv}\n",
    "        metrics.append(metrics_dict) # per combination of mlp-bs, and per fold\n",
    "        pop_biases = [pop_bias]\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05c3e02e-93ca-4165-886a-fa65c82b26fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pop_corr': (0.002419312870633217, 0.8405165908437839),\n",
       " 'RMSE': 0,\n",
       " 'NDCG': 0.001639807446294823,\n",
       " 'ARP': 0.002071079667867551,\n",
       " 'ave_PL': -42.53959701238517,\n",
       " 'ACLT': 5.584905660377358,\n",
       " 'AggDiv': 0.009247218610027452}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b30dbe-3ec9-4854-9f50-25d8b88b0301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64-64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_location' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m      6\u001b[0m     recs_file \u001b[38;5;241m=\u001b[39m final_recs_files[mlp]\n\u001b[0;32m----> 7\u001b[0m     train_file \u001b[38;5;241m=\u001b[39m \u001b[43mdata_location\u001b[49m\u001b[38;5;241m+\u001b[39mdata\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fold_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fold)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m     test_file \u001b[38;5;241m=\u001b[39m data_location\u001b[38;5;241m+\u001b[39mdata\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fold_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fold)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print(recs_file)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_location' is not defined"
     ]
    }
   ],
   "source": [
    "for mlp in mlp_values:\n",
    "    metrics = []\n",
    "    print(mlp)\n",
    "    for fold in range(1,6):\n",
    "        \n",
    "        recs_file = final_recs_files[]\n",
    "        train_file = data_location+data+'_fold_'+str(fold)+'_train.csv'\n",
    "        test_file = data_location+data+'_fold_'+str(fold)+'_test.csv'\n",
    "        # print(recs_file)\n",
    "        recs_df = pd.read_csv(recs_file, sep='\\t', header=None)\n",
    "        recs_df.columns = ['user','item','rating']\n",
    "        train_df = pd.read_csv(train_file)\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        test_users = test_df.user.unique()\n",
    "        test_recs = recs_df[recs_df.user.isin(test_users)].reset_index(drop=True)\n",
    "        test_recs_grouped = test_recs.groupby([user_col])[item_col].apply(list)\n",
    "        \n",
    "        pop_bias= modelling_mf.calculate_pop_bias_per_item(all_items, item_col, user_col, predict_col, train_df, recs=test_recs)\n",
    "        GAP_vs_GAP = modelling_mf.calculate_ave_pop_per_user(test_users, item_col, user_col, pop_bias, train_df, test_recs_grouped)\n",
    "        pop_corr = modelling_mf.calculate_pop_correlation(pop_bias)\n",
    "        precision, recall, ndcg = modelling_mf.calculate_topn_metrics(test_recs,test_df)\n",
    "        AggDiv = modelling_mf.evaluate_item_coverage(pop_bias[\"recommendation\"].values)\n",
    "        ARP, ave_PL, ACLT = modelling_mf.calculate_all_pb_metrics(pop_bias, test_users, item_col, user_col, train_df, test_recs_grouped, test_recs)\n",
    "        metrics_dict = {\"pop_corr\":pop_corr, \"RMSE\":0, 'NDCG':ndcg,\"ARP\":ARP, \"ave_PL\": ave_PL, \"ACLT\": ACLT, \"AggDiv\": AggDiv}\n",
    "        metrics.append(metrics_dict) # per combination of mlp-bs, and per fold\n",
    "        pop_biases = [pop_bias]\n",
    "        \n",
    "        modelling_mf.plot_results(pop_biases.copy(), \n",
    "                 GAP_vs_GAP.copy(), algorithm,\n",
    "                 0, \n",
    "                 precision, \n",
    "                 recall,\n",
    "                 ndcg,\n",
    "                 0,\n",
    "                 0,\n",
    "                 cv=False, \n",
    "                 n=10, \n",
    "                 args='fold'+str(fold), data_strategy=data, save_plot=False)\n",
    "        \n",
    "    full_metrics_dict[mlp] = metrics\n",
    "    print(full_metrics_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
