{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8bf83-ac62-42d2-94e5-edc33cde3779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from elliot.run import run_experiment\n",
    "import zipfile\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "import numpy as np\n",
    "import os\n",
    "from lenskit import crossfold as xf\n",
    "from lib.data_generation import generate_data\n",
    "from itertools import chain\n",
    "from lenskit import util, batch, topn\n",
    "from lib import modelling_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065379c-f189-4f27-8469-0fad28351ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"fairbook\"\n",
    "# user-item interactions\n",
    "fairbook_ratings = pd.read_csv(\"data/fairbook/\"+data+\"_events.csv\")\n",
    "\n",
    "user_col = \"user\" # the name of the column that includes the users\n",
    "item_col = \"item\" # the name of the column that includes the items\n",
    "predict_col=\"rating\" # the name of the column that includes the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c5bfb-83ef-4616-b583-c815844dd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'DMF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04619d5f-696d-44e5-818d-448552c2c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible values for the hyperparameters\n",
    "mlp_values = ['64-32', '64-64']\n",
    "batch_size_values = ['256', '512']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12cce2f-6d0b-43ed-be5a-1c41eb1f0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_strategies = ['uniformly_random',\n",
    "                   'popularity_good',\n",
    "                   'popularity_bad',\n",
    "                   'popularity_good_for_bp_ur',\n",
    "                   'popularity_bad_for_bp_ur']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90d270-3ab9-40c4-be34-e95c7d8619a7",
   "metadata": {},
   "source": [
    "#### Uniformly random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba71ec-ca85-40b8-ae28-1fda52420e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0 # only thing that needs to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9f5ba-c493-4e69-ba62-0d24de5df9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = generate_data(strategy = data_strategies[j],\n",
    "                            copying_dataset = fairbook_ratings,\n",
    "                            user_perc = 0.2)\n",
    "all_items=set(ratings.item.unique())\n",
    "full_metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85a11f-26f8-4bf1-82e9-af412fbe621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mlp in mlp_values:\n",
    "    for batch_size in batch_size_values:\n",
    "        metrics = []\n",
    "        print(mlp, batch_size)\n",
    "        for fold in range(1,6):\n",
    "            recs_location = 'results/'+data_strategies[j]+str(fold)+'/recs/'\n",
    "            data_location = 'data/'+data_strategies[j]+str(fold)+'/'\n",
    "            recs_file = recs_location + algorithm+'_seed=42_e=10_bs='+batch_size+'_lr=0$0001_umlp='+mlp+'_imlp='+mlp+'_negratio=5_reg=0$001_sim=cosine_it=10.tsv'\n",
    "            train_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_train.csv'\n",
    "            test_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_test.csv'\n",
    "            # print(recs_file)\n",
    "            recs_df = pd.read_csv(recs_file, sep='\\t', header=None)\n",
    "            recs_df.columns = ['user','item','rating']\n",
    "            train_df = pd.read_csv(train_file)\n",
    "            test_df = pd.read_csv(test_file)\n",
    "            test_users = test_df.user.unique()\n",
    "            test_recs = recs_df[recs_df.user.isin(test_users)].reset_index(drop=True)\n",
    "            test_recs_grouped = test_recs.groupby([user_col])[item_col].apply(list)\n",
    "            \n",
    "            pop_bias= modelling_mf.calculate_pop_bias_per_item(all_items, item_col, user_col, predict_col, train_df, recs=test_recs)\n",
    "            GAP_vs_GAP = modelling_mf.calculate_ave_pop_per_user(test_users, item_col, user_col, pop_bias, train_df, test_recs_grouped)\n",
    "            pop_corr = modelling_mf.calculate_pop_correlation(pop_bias)\n",
    "            precision, recall, ndcg = modelling_mf.calculate_topn_metrics(test_recs,test_df)\n",
    "            AggDiv = modelling_mf.evaluate_item_coverage(pop_bias[\"recommendation\"].values)\n",
    "            ARP, ave_PL, ACLT = modelling_mf.calculate_all_pb_metrics(pop_bias, test_users, item_col, user_col, train_df, test_recs_grouped, test_recs)\n",
    "            metrics_dict = {\"pop_corr\":pop_corr, \"RMSE\":0, 'NDCG':ndcg,\"ARP\":ARP, \"ave_PL\": ave_PL, \"ACLT\": ACLT, \"AggDiv\": AggDiv}\n",
    "            metrics.append(metrics_dict) # per combination of mlp-bs, and per fold\n",
    "            pop_biases = [pop_bias]\n",
    "            \n",
    "            modelling_mf.plot_results(pop_biases.copy(), \n",
    "                     GAP_vs_GAP.copy(), algorithm,\n",
    "                     0, \n",
    "                     precision, \n",
    "                     recall,\n",
    "                     ndcg,\n",
    "                     0,\n",
    "                     0,\n",
    "                     cv=False, \n",
    "                     n=10, \n",
    "                     args='fold'+str(fold), data_strategy=data_strategies[j], save_plot=False)\n",
    "            \n",
    "        full_metrics_dict[(mlp, batch_size)] = metrics\n",
    "        print(full_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0c129-1379-4b4d-8546-8afeb2b01720",
   "metadata": {},
   "outputs": [],
   "source": [
    "ur_metrics = full_metrics_dict.copy() # not done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b92fb7-798b-4b3b-bb87-04a52a4c2827",
   "metadata": {},
   "source": [
    "#### Popularity good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfd51f-e7d8-4061-a348-5bcfdb4d95d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1 # only thing that needs to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8219b55c-778d-4c41-bfe5-b4c9179bcf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = generate_data(strategy = data_strategies[j],\n",
    "                            copying_dataset = fairbook_ratings,\n",
    "                            user_perc = 0.2)\n",
    "all_items=set(ratings.item.unique())\n",
    "full_metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e7d8e-54ef-4b97-b314-63c0bdd32e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mlp in mlp_values:\n",
    "    for batch_size in batch_size_values:\n",
    "        metrics = []\n",
    "        print(mlp, batch_size)\n",
    "        for fold in range(1,6):\n",
    "            recs_location = 'results/'+data_strategies[j]+str(fold)+'/recs/'\n",
    "            data_location = 'data/'+data_strategies[j]+str(fold)+'/'\n",
    "            recs_file = recs_location + algorithm+'_seed=42_e=10_bs='+batch_size+'_lr=0$0001_umlp='+mlp+'_imlp='+mlp+'_negratio=5_reg=0$001_sim=cosine_it=10.tsv'\n",
    "            train_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_train.csv'\n",
    "            test_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_test.csv'\n",
    "            # print(recs_file)\n",
    "            recs_df = pd.read_csv(recs_file, sep='\\t', header=None)\n",
    "            recs_df.columns = ['user','item','rating']\n",
    "            train_df = pd.read_csv(train_file)\n",
    "            test_df = pd.read_csv(test_file)\n",
    "            test_users = test_df.user.unique()\n",
    "            test_recs = recs_df[recs_df.user.isin(test_users)].reset_index(drop=True)\n",
    "            test_recs_grouped = test_recs.groupby([user_col])[item_col].apply(list)\n",
    "            \n",
    "            pop_bias= modelling_mf.calculate_pop_bias_per_item(all_items, item_col, user_col, predict_col, train_df, recs=test_recs)\n",
    "            GAP_vs_GAP = modelling_mf.calculate_ave_pop_per_user(test_users, item_col, user_col, pop_bias, train_df, test_recs_grouped)\n",
    "            pop_corr = modelling_mf.calculate_pop_correlation(pop_bias)\n",
    "            precision, recall, ndcg = modelling_mf.calculate_topn_metrics(test_recs,test_df)\n",
    "            AggDiv = modelling_mf.evaluate_item_coverage(pop_bias[\"recommendation\"].values)\n",
    "            ARP, ave_PL, ACLT = modelling_mf.calculate_all_pb_metrics(pop_bias, test_users, item_col, user_col, train_df, test_recs_grouped, test_recs)\n",
    "            metrics_dict = {\"pop_corr\":pop_corr, \"RMSE\":0, 'NDCG':ndcg,\"ARP\":ARP, \"ave_PL\": ave_PL, \"ACLT\": ACLT, \"AggDiv\": AggDiv}\n",
    "            metrics.append(metrics_dict) # per combination of mlp-bs, and per fold\n",
    "            pop_biases = [pop_bias]\n",
    "            \n",
    "            modelling_mf.plot_results(pop_biases.copy(), \n",
    "                     GAP_vs_GAP.copy(), algorithm,\n",
    "                     0, \n",
    "                     precision, \n",
    "                     recall,\n",
    "                     ndcg,\n",
    "                     0,\n",
    "                     0,\n",
    "                     cv=False, \n",
    "                     n=10, \n",
    "                     args='fold'+str(fold), data_strategy=data_strategies[j], save_plot=False)\n",
    "            \n",
    "        full_metrics_dict[(mlp, batch_size)] = metrics\n",
    "        print(full_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e1dbf-7009-463a-9897-9a17e58cb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_metrics = full_metrics_dict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c7c58-298b-463b-8984-e4a365db060a",
   "metadata": {},
   "source": [
    "#### Popularity bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be143a56-9a23-41fc-93de-cae8e02c7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 2 # only thing that needs to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540b8cf3-928d-484f-a436-692635460742",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = generate_data(strategy = data_strategies[j],\n",
    "                            copying_dataset = fairbook_ratings,\n",
    "                            user_perc = 0.2)\n",
    "all_items=set(ratings.item.unique())\n",
    "full_metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4a6b2-5b83-46d2-b970-05ef2d009d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mlp in mlp_values:\n",
    "    for batch_size in batch_size_values:\n",
    "        metrics = []\n",
    "        print(mlp, batch_size)\n",
    "        for fold in range(1,6):\n",
    "            recs_location = 'results/'+data_strategies[j]+str(fold)+'/recs/'\n",
    "            data_location = 'data/'+data_strategies[j]+str(fold)+'/'\n",
    "            recs_file = recs_location + algorithm+'_seed=42_e=10_bs='+batch_size+'_lr=0$0001_umlp='+mlp+'_imlp='+mlp+'_negratio=5_reg=0$001_sim=cosine_it=10.tsv'\n",
    "            train_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_train.csv'\n",
    "            test_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_test.csv'\n",
    "            # print(recs_file)\n",
    "            recs_df = pd.read_csv(recs_file, sep='\\t', header=None)\n",
    "            recs_df.columns = ['user','item','rating']\n",
    "            train_df = pd.read_csv(train_file)\n",
    "            test_df = pd.read_csv(test_file)\n",
    "            test_users = test_df.user.unique()\n",
    "            test_recs = recs_df[recs_df.user.isin(test_users)].reset_index(drop=True)\n",
    "            test_recs_grouped = test_recs.groupby([user_col])[item_col].apply(list)\n",
    "            \n",
    "            pop_bias= modelling_mf.calculate_pop_bias_per_item(all_items, item_col, user_col, predict_col, train_df, recs=test_recs)\n",
    "            GAP_vs_GAP = modelling_mf.calculate_ave_pop_per_user(test_users, item_col, user_col, pop_bias, train_df, test_recs_grouped)\n",
    "            pop_corr = modelling_mf.calculate_pop_correlation(pop_bias)\n",
    "            precision, recall, ndcg = modelling_mf.calculate_topn_metrics(test_recs,test_df)\n",
    "            AggDiv = modelling_mf.evaluate_item_coverage(pop_bias[\"recommendation\"].values)\n",
    "            ARP, ave_PL, ACLT = modelling_mf.calculate_all_pb_metrics(pop_bias, test_users, item_col, user_col, train_df, test_recs_grouped, test_recs)\n",
    "            metrics_dict = {\"pop_corr\":pop_corr, \"RMSE\":0, 'NDCG':ndcg,\"ARP\":ARP, \"ave_PL\": ave_PL, \"ACLT\": ACLT, \"AggDiv\": AggDiv}\n",
    "            metrics.append(metrics_dict) # per combination of mlp-bs, and per fold\n",
    "            pop_biases = [pop_bias]\n",
    "            \n",
    "            modelling_mf.plot_results(pop_biases.copy(), \n",
    "                     GAP_vs_GAP.copy(), algorithm,\n",
    "                     0, \n",
    "                     precision, \n",
    "                     recall,\n",
    "                     ndcg,\n",
    "                     0,\n",
    "                     0,\n",
    "                     cv=False, \n",
    "                     n=10, \n",
    "                     args='fold'+str(fold), data_strategy=data_strategies[j], save_plot=False)\n",
    "            \n",
    "        full_metrics_dict[(mlp, batch_size)] = metrics\n",
    "        print(full_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f8bf3-8955-4061-9ac6-fd66c3ba05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_metrics = full_metrics_dict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee71a4-4a03-4b89-9d43-119b21894ea3",
   "metadata": {},
   "source": [
    "#### Popularity good big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe3ad8-0418-4742-87cf-534ac006225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 3 # only thing that needs to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89082f44-a5b5-4163-bfb9-b0f7649581ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = generate_data(strategy = data_strategies[j],\n",
    "                            copying_dataset = fairbook_ratings,\n",
    "                            user_perc = 0.2)\n",
    "all_items=set(ratings.item.unique())\n",
    "full_metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d782d-44a2-489a-bdb6-4f2d2d2d9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt = 'popularity_good_big' # different title due to mistake\n",
    "for mlp in mlp_values:\n",
    "    for batch_size in batch_size_values:\n",
    "        metrics = []\n",
    "        print(mlp, batch_size)\n",
    "        for fold in range(1,6):\n",
    "            recs_location = 'results/'+alt+str(fold)+'/recs/'\n",
    "            data_location = 'data/'+alt+str(fold)+'/'\n",
    "            recs_file = recs_location + algorithm+'_seed=42_e=10_bs='+batch_size+'_lr=0$0001_umlp='+mlp+'_imlp='+mlp+'_negratio=5_reg=0$001_sim=cosine_it=10.tsv'\n",
    "            train_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_train.csv'\n",
    "            test_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_test.csv'\n",
    "            # print(recs_file)\n",
    "            recs_df = pd.read_csv(recs_file, sep='\\t', header=None)\n",
    "            recs_df.columns = ['user','item','rating']\n",
    "            train_df = pd.read_csv(train_file)\n",
    "            test_df = pd.read_csv(test_file)\n",
    "            test_users = test_df.user.unique()\n",
    "            test_recs = recs_df[recs_df.user.isin(test_users)].reset_index(drop=True)\n",
    "            test_recs_grouped = test_recs.groupby([user_col])[item_col].apply(list)\n",
    "            \n",
    "            pop_bias= modelling_mf.calculate_pop_bias_per_item(all_items, item_col, user_col, predict_col, train_df, recs=test_recs)\n",
    "            GAP_vs_GAP = modelling_mf.calculate_ave_pop_per_user(test_users, item_col, user_col, pop_bias, train_df, test_recs_grouped)\n",
    "            pop_corr = modelling_mf.calculate_pop_correlation(pop_bias)\n",
    "            precision, recall, ndcg = modelling_mf.calculate_topn_metrics(test_recs,test_df)\n",
    "            AggDiv = modelling_mf.evaluate_item_coverage(pop_bias[\"recommendation\"].values)\n",
    "            ARP, ave_PL, ACLT = modelling_mf.calculate_all_pb_metrics(pop_bias, test_users, item_col, user_col, train_df, test_recs_grouped, test_recs)\n",
    "            metrics_dict = {\"pop_corr\":pop_corr, \"RMSE\":0, 'NDCG':ndcg,\"ARP\":ARP, \"ave_PL\": ave_PL, \"ACLT\": ACLT, \"AggDiv\": AggDiv}\n",
    "            metrics.append(metrics_dict) # per combination of mlp-bs, and per fold\n",
    "            pop_biases = [pop_bias]\n",
    "            \n",
    "            modelling_mf.plot_results(pop_biases.copy(), \n",
    "                     GAP_vs_GAP.copy(), algorithm,\n",
    "                     0, \n",
    "                     precision, \n",
    "                     recall,\n",
    "                     ndcg,\n",
    "                     0,\n",
    "                     0,\n",
    "                     cv=False, \n",
    "                     n=10, \n",
    "                     args='fold'+str(fold), data_strategy=data_strategies[j], save_plot=False)\n",
    "            \n",
    "        full_metrics_dict[(mlp, batch_size)] = metrics\n",
    "        print(full_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dcb0fe-06e4-4b58-a767-0083fd5fb857",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_bp_metrics = full_metrics_dict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336a2b3-978b-409a-9c4e-30b6f8b67389",
   "metadata": {},
   "source": [
    "#### Popularity bad big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0296c-8c8f-441a-9e64-801702ef751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 4 # only thing that needs to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2bdf1b-33f5-45d8-a425-fdf9a6d1e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = generate_data(strategy = data_strategies[j],\n",
    "                            copying_dataset = fairbook_ratings,\n",
    "                            user_perc = 0.2)\n",
    "all_items=set(ratings.item.unique())\n",
    "full_metrics_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5429bc-21bb-463c-83a8-c6521413f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt = 'popularity_bad_big' # different title due to mistake\n",
    "for mlp in mlp_values:\n",
    "    for batch_size in batch_size_values:\n",
    "        metrics = []\n",
    "        print(mlp, batch_size)\n",
    "        for fold in range(1,6):\n",
    "            recs_location = 'results/'+alt+str(fold)+'/recs/'\n",
    "            data_location = 'data/'+alt+str(fold)+'/'\n",
    "            recs_file = recs_location + algorithm+'_seed=42_e=10_bs='+batch_size+'_lr=0$0001_umlp='+mlp+'_imlp='+mlp+'_negratio=5_reg=0$001_sim=cosine_it=10.tsv'\n",
    "            train_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_train.csv'\n",
    "            test_file = data_location+data_strategies[j]+'_fold_'+str(fold)+'_test.csv'\n",
    "            # print(recs_file)\n",
    "            recs_df = pd.read_csv(recs_file, sep='\\t', header=None)\n",
    "            recs_df.columns = ['user','item','rating']\n",
    "            train_df = pd.read_csv(train_file)\n",
    "            test_df = pd.read_csv(test_file)\n",
    "            test_users = test_df.user.unique()\n",
    "            test_recs = recs_df[recs_df.user.isin(test_users)].reset_index(drop=True)\n",
    "            test_recs_grouped = test_recs.groupby([user_col])[item_col].apply(list)\n",
    "            \n",
    "            pop_bias= modelling_mf.calculate_pop_bias_per_item(all_items, item_col, user_col, predict_col, train_df, recs=test_recs)\n",
    "            GAP_vs_GAP = modelling_mf.calculate_ave_pop_per_user(test_users, item_col, user_col, pop_bias, train_df, test_recs_grouped)\n",
    "            pop_corr = modelling_mf.calculate_pop_correlation(pop_bias)\n",
    "            precision, recall, ndcg = modelling_mf.calculate_topn_metrics(test_recs,test_df)\n",
    "            AggDiv = modelling_mf.evaluate_item_coverage(pop_bias[\"recommendation\"].values)\n",
    "            ARP, ave_PL, ACLT = modelling_mf.calculate_all_pb_metrics(pop_bias, test_users, item_col, user_col, train_df, test_recs_grouped, test_recs)\n",
    "            metrics_dict = {\"pop_corr\":pop_corr, \"RMSE\":0, 'NDCG':ndcg,\"ARP\":ARP, \"ave_PL\": ave_PL, \"ACLT\": ACLT, \"AggDiv\": AggDiv}\n",
    "            metrics.append(metrics_dict) # per combination of mlp-bs, and per fold\n",
    "            pop_biases = [pop_bias]\n",
    "            \n",
    "            modelling_mf.plot_results(pop_biases.copy(), \n",
    "                     GAP_vs_GAP.copy(), algorithm,\n",
    "                     0, \n",
    "                     precision, \n",
    "                     recall,\n",
    "                     ndcg,\n",
    "                     0,\n",
    "                     0,\n",
    "                     cv=False, \n",
    "                     n=10, \n",
    "                     args='fold'+str(fold), data_strategy=data_strategies[j], save_plot=False)\n",
    "            \n",
    "        full_metrics_dict[(mlp, batch_size)] = metrics\n",
    "        print(full_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac71737-c988-4baa-a513-457d175a8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_bp_metrics = full_metrics_dict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3cdc7-b40a-4c12-9d67-a413fdcc4e0a",
   "metadata": {},
   "source": [
    "## Combine results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da7620-430c-454b-897b-cba38c14e6cf",
   "metadata": {},
   "source": [
    "Now I have to figure out how to combine the results in a way that makes sense..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689405e-da4a-4df7-a1a7-87232a23e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [ur_metrics, pg_metrics, pb_metrics, pg_bp_metrics, pb_bp_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac9fbd-c9e2-438b-8045-0a7e01d7cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_values = [\"pop_corr\", \"ARP\", \"ave_PL\", \"AggDiv\", \"NDCG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726b9ea-9fc0-46f2-a55e-737838155609",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(ur_metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39ef0c-16a1-4567-9b84-1a2348854d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689c935-0db3-4cd8-b98a-80b37e03dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_list = []\n",
    "for strategy in metrics_list:\n",
    "    curr_list = []\n",
    "    for param in params: # for every instantiation of the algo\n",
    "        # print(strategy)\n",
    "        met = strategy[param]\n",
    "    \n",
    "        curr_dict = {}\n",
    "        for value in relevant_values:\n",
    "            ave_value = sum(d[value] for d in met) / len(met)\n",
    "            # print(ave_value)\n",
    "            curr_dict[value] = ave_value\n",
    "            \n",
    "        curr_list.append(curr_dict)\n",
    "    strategy_list.append(curr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d14ad2-1839-4fe1-bb5c-fb11272f5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d2701-51c0-4f61-a2e1-9bccbc76b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [\"Scenario 1\", \"Scenario 2\", \"Scenario 3\", \"Scenario 4\", \"Scenario 5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45dca71-1723-4a95-893c-921be86d3622",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = np.unique([x[0] for x in params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccde506-f955-4688-9b37-e69a9f87ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = np.unique([x[1] for x in params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78cb1d-b353-44bc-a8ad-c1fa4b1702ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_product(\n",
    "    [ds, layers, batches], names=[\"DataStrategy\", \"Layers\", \"Batches\"]\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f1f5e-2788-41ff-be24-451055203769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unlisted_sl = list(chain(*strategy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d8286-b585-4764-8b9b-2947d8cf76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(unlisted_sl, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ca469-f942-4c38-b5d5-78b1d007811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.round(3).to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
